{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LQtJ86nzNnCmAy8ZNbw0AJeRuf6S3iSF","timestamp":1668971053516}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lHs7ywqw20Jr"},"source":["# Práctica 4 - Filtrado de Spam usando Bayes Ingenuo\n","\n","Guarda una copia de este cuaderno en tu Google Drive para poder editarla y ejecutarla.\n","\n","El propio cuaderno será tu informe de la práctica. Puedes añadir tantas secciones de código y de texto como consideres necesario para resolver todos los ejercicios propuestos y analizar los resultados obtenidos. Una vez hayas terminado, descarga el notebook en formato ipynb y súbelo a Moodle en la tarea habilitada para la P4 con el nombre NIP_P4.ipynb"]},{"cell_type":"markdown","metadata":{"id":"E0VmxZqbSZkh"},"source":["Imports necesarios para ejecutar la práctica"]},{"cell_type":"code","metadata":{"id":"5eMdo6XcI-8G","executionInfo":{"status":"ok","timestamp":1669063386369,"user_tz":-60,"elapsed":660,"user":{"displayName":"Dorian Wozniak","userId":"02459404773539009868"}}},"source":["import numpy as np\n","import json\n","import glob\n","import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.utils import shuffle\n","from sklearn import metrics\n","from sklearn.model_selection import KFold"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vaaAoKT8Sdoi"},"source":["Carga del fichero ZIP con todos los correos"]},{"cell_type":"code","metadata":{"id":"Ju6jVmIFGdaE"},"source":["!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1hYha8kSpbAhGIHAfygLFmGHIzHGAK5f8' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1hYha8kSpbAhGIHAfygLFmGHIzHGAK5f8\" -O \"enron.zip\" && rm -rf /tmp/cookies.txt\n","!unzip \"enron.zip\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j2uujVbYSO9x"},"source":["Lectura de los emails y carga en las estructuras de datos"]},{"cell_type":"code","metadata":{"id":"ti5yXHPpOpAr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669067653487,"user_tz":-60,"elapsed":6980,"user":{"displayName":"Dorian Wozniak","userId":"02459404773539009868"}},"outputId":"7249cf99-d539-4ed4-9e03-ddd78490c5f1"},"source":["def read_folder(folder):\n","    mails = []\n","    file_list = glob.glob(folder)  # List mails in folder\n","    num_files = len(file_list)\n","    for i in range(0, num_files):\n","        i_path = file_list[i]\n","        i_file = open(i_path, 'rb')\n","        i_str = i_file.read()\n","        i_text = i_str.decode('utf-8', errors='ignore')  # Convert to Unicode\n","        mails.append(i_text)  # Append to the mail structure\n","        i_file.close()\n","    return mails\n","\n","def load_enron_folders(datasets):\n","    path = './'\n","    ham = []\n","    spam = []\n","    for j in datasets:\n","        ham  = ham  + read_folder(path + '/enron' + str(j) + '/ham/*.txt')\n","        spam = spam + read_folder(path + '/enron' + str(j) + '/spam/*.txt')\n","    num_ham  = len(ham)\n","    num_spam = len(spam)\n","    print(\"mails:\", num_ham+num_spam)\n","    print(\"ham  :\", num_ham)\n","    print(\"spam :\", num_spam)\n","\n","    mails = ham + spam\n","    labels = [0]*num_ham + [1]*num_spam\n","    mails, labels = shuffle(mails, labels, random_state=0)\n","    return mails, labels\n","\n","print(\"Loading files...\")\n","\n","print(\"------Loading train and validation data--------\")\n","mails, y = load_enron_folders([1,2,3,4,5])\n","\n","print(\"--------------Loading Test data----------------\")\n","mails_test, y_test = load_enron_folders([6])"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading files...\n","------Loading train and validation data--------\n","mails: 27716\n","ham  : 15045\n","spam : 12671\n","--------------Loading Test data----------------\n","mails: 6000\n","ham  : 1500\n","spam : 4500\n"]}]},{"cell_type":"markdown","metadata":{"id":"0-a8BMyQS13B"},"source":["Código para generar una bolsa de palabras que cuenta el número de apariciones de cada palabra en la lista de correos\n","\n","Crea una matriz X con tantas filas como correos (27716) y tantas columnas como palabras de la BD. El elemento (i,j) de la matriz contiene el número de ocurrencias de la palabra j en el correo i"]},{"cell_type":"code","metadata":{"id":"O8Fz7j4iBRh0","executionInfo":{"status":"ok","timestamp":1669063408891,"user_tz":-60,"elapsed":8121,"user":{"displayName":"Dorian Wozniak","userId":"02459404773539009868"}}},"source":["vectorizer  = CountVectorizer(ngram_range=(1, 1))  # Instancia de bolsa de palabras con palabras individuales como características\n","X = vectorizer.fit_transform(mails)                # Generación y cálculo de la bolsa de palabras en base a los datos de entrenamiento\n","X_test = vectorizer.transform(mails_test)          # Cáclulo de la bolsa de palabras con los datos de test"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G90GpsJ5UKBI"},"source":["Aprendizaje de las probabilidades utilizando un modelo de distribución Bernoulli.\n","\n","Consulta la documentación de sklearn para entender los parámetros."]},{"cell_type":"code","metadata":{"id":"NDeOtoAKTGyy"},"source":["classifier = BernoulliNB(alpha=1.0, fit_prior=True, class_prior=None) # Instancia de clasificador de Bayes Ingenuo con distribución de Bernoulli\n","classifier.fit(X,y) # Cálculo de las probabilidades asociadas a cada palabra de la bolsa"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u1Zc5brWUHqQ"},"source":["Cálculo de métricas del clasificador utilizando los datos de test"]},{"cell_type":"code","metadata":{"id":"MLhvnRYGUG_r"},"source":["y_pred = classifier.predict(X_test)\n","f1_score=metrics.f1_score(y_test, y_pred)\n","print('%s %2.2f%s' % ('F1-score of the test: ', 100*f1_score, '%' ))\n","C=metrics.confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(C)\n","metrics.plot_precision_recall_curve(classifier,X_test,y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. Clasificador Bayes ingénuo\n","\n","### 1.1. Distribución binomial"],"metadata":{"id":"aQgez7_dfU00"}},{"cell_type":"code","source":["# Chapuza para suprimir avisos de la funcion plot \n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","# Crea y obtiene métricas para un clasificador mediante Bayes ingénuo utliizando\n","# distribuciones binomiales \n","#\n","# suavizado: Hiperparámetro de suavizado de Laplace\n","# imprConfusion: Imprime matriz confusión\n","# imprPR: Imprime gráfica precision-recall\n","def bayesIngenuoBernoulli(suavizado, imprConfusion = False, imprPR = False):\n","  # Instancia el clasificador\n","  clasificador = BernoulliNB(alpha = suavizado)\n","\n","  # Calcula probabilidades utilizando los datos de entrenamiento\n","  clasificador.fit(X,y)\n","\n","  # Realiza clasificación con los datos de prueba\n","  y_prediccion = clasificador.predict(X_test)\n","  print(\"Bayes ingénuo, distribución binomial, suavizado = %2.2f\" % (suavizado))\n","\n","  # Puntuación F1\n","  f1_score = metrics.f1_score(y_test, y_prediccion)\n","  print(\"\\nPuntuación F1: %2.2f\" % (100 * f1_score))\n","\n","  # Matriz de confusión\n","  if imprConfusion:\n","    confusion = metrics.confusion_matrix(y_test, y_prediccion)\n","    print(\"Matriz de confusión:\")\n","    print(confusion)\n","\n","  # Recta precision-recall\n","  if imprPR:\n","    metrics.plot_precision_recall_curve(clasificador, X_test, y_test)\n","\n","  print(\"\\n\")\n","\n","  return f1_score\n","\n","bayesIngenuoBernoulli(1.0, True, True)\n"],"metadata":{"id":"PReVL470f-7o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.2. Distribución multinomial"],"metadata":{"id":"Na-uW0G6f_Uh"}},{"cell_type":"code","source":["# Crea y obtiene métricas para un clasificador mediante Bayes ingénuo utliizando\n","# distribuciones multinomiales. Imprime métricas y devuelve la puntuación F1\n","#\n","# suavizado: Hiperparámetro de suavizado de Laplace\n","# imprConfusion: Imprime matriz confusión\n","# imprPR: Imprime gráfica precision-recall\n","def bayesIngenuoMultinomial(suavizado, imprConfusion = False, imprPR = False):\n","  # Instancia el clasificador\n","  clasificador = MultinomialNB(alpha = suavizado)\n","\n","  # Calcula probabilidades utilizando los datos de entrenamiento\n","  clasificador.fit(X,y)\n","\n","  # Realiza clasificación con los datos de prueba\n","  y_prediccion = clasificador.predict(X_test)\n","  print(\"Bayes ingénuo, distribución multinomial, suavizado = %2.2f\" % (suavizado))\n","\n","  # Puntuación F1\n","  f1_score = metrics.f1_score(y_test, y_prediccion)\n","  print(\"\\nPuntuación F1: %2.2f\" % (100 * f1_score))\n","\n","  # Matriz de confusión\n","  if imprConfusion:\n","    confusion = metrics.confusion_matrix(y_test, y_prediccion)\n","    print(\"Matriz de confusión:\")\n","    print(confusion)\n","\n","  # Recta precision-recall\n","  if imprPR:\n","    metrics.plot_precision_recall_curve(clasificador, X_test, y_test)\n","\n","  print(\"\\n\")\n","\n","  return f1_score\n","\n","\n","bayesIngenuoMultinomial(1.0, True, True)"],"metadata":{"id":"qVuTefCbgEdJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Pruebas según el hiperparámetro de suavizado de Laplace\n","\n","### 2.1. Distribución binomial"],"metadata":{"id":"jmb4cxfQgEtI"}},{"cell_type":"code","source":["# Obtiene el mejor suavizado a partir de la puntuación F1\n","# Bayes ingénuo binomial\n","def mejorSuavizadoBinomial():\n","  mejor_f1 = 0.0\n","  mejor_suavizado = 0.0\n","  i = 0.1\n","\n","  while i <= 2.0:\n","    f1_score = bayesIngenuoBernoulli(i)\n","\n","    if f1_score > mejor_f1:\n","      mejor_f1 = f1_score\n","      mejor_suavizado = i\n","\n","    i+=0.05\n","\n","  print(\"El hiperparámetro %2.2f ha dado el mejor resultado con una puntuación de %2.2f\" % (mejor_suavizado, 100*mejor_f1))\n","\n","  return (mejor_suavizado, 100*mejor_f1)\n","\n","mejorSuavizadoBinomial()  "],"metadata":{"id":"3CXDsJ7hgU31"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.2. Distribución multinomial"],"metadata":{"id":"d_z5KurTgVMR"}},{"cell_type":"code","source":["# Obtiene el mejor suavizado a partir de la puntuación F1\n","# Bayes ingénuo multinomial\n","def mejorSuavizadoMultinomial():\n","  mejor_f1 = 0.0\n","  mejor_suavizado = 0.0\n","  i = 0.1\n","\n","  while i <= 2.0:\n","    f1_score = bayesIngenuoMultinomial(i)\n","\n","    if (f1_score) > mejor_f1:\n","      mejor_f1 = f1_score\n","      mejor_suavizado = i\n","    \n","    i+=0.05\n","\n","  print(\"El hiperparámetro %2.2f ha dado el mejor resultado con una puntuación de %2.2f\" % (mejor_suavizado, 100*mejor_f1))\n","  return (mejor_suavizado, 100*mejor_f1)\n","\n","\n","mejorSuavizadoMultinomial()"],"metadata":{"id":"IME5YMC5gfih"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Utilización de bigramas"],"metadata":{"id":"U8a-XpRsgkxJ"}},{"cell_type":"code","source":["# Genera y calcula la bolsa de palabras, esta vez pasando de generar\n","# unigramas a partir de las palabras a bigramas\n","\n","vectorizer  = CountVectorizer(ngram_range=(1, 2))\n","X = vectorizer.fit_transform(mails)          \n","X_test = vectorizer.transform(mails_test)\n","\n","mejorSuavizadoBinomial()\n","print(\"\\n\")\n","mejorSuavizadoMultinomial()"],"metadata":{"id":"PTLoDcQego9c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Evaluación del mejor clasificador"],"metadata":{"id":"MiVFpWHSgw6Q"}},{"cell_type":"code","source":["# Prueba distintas combinaciones utilizando solo el F1 para comparar\n","\n","vectorizer  = CountVectorizer(ngram_range=(1, 1))\n","X = vectorizer.fit_transform(mails)          \n","X_test = vectorizer.transform(mails_test)\n","\n","mejor_binomial_unigrama = mejorSuavizadoBinomial()\n","print(\"\\n\")\n","mejor_multinomial_unigrama = mejorSuavizadoMultinomial()\n","\n","vectorizer  = CountVectorizer(ngram_range=(1, 2))\n","X = vectorizer.fit_transform(mails)          \n","X_test = vectorizer.transform(mails_test)\n","\n","mejor_binomial_bigrama = mejorSuavizadoBinomial()\n","print(\"\\n\")\n","mejor_multinomial_bigrama = mejorSuavizadoMultinomial()\n","print(\"\\n\")\n","\n","print(\"De entre los casos analizados, los mejores F1 son:\")\n","\n","print(\"Unigrama-binomial: Suavizado = %2.2f, F1 = %2.2f\" % ((mejor_binomial_unigrama[0], mejor_binomial_unigrama[1])))\n","print(\"Unigrama-multinomial: Suavizado = %2.2f, F1 = %2.2f\" % ((mejor_multinomial_unigrama[0], mejor_multinomial_unigrama[1])))\n","print(\"Bigrama-binomial: Suavizado = %2.2f, F1 = %2.2f\" % ((mejor_binomial_bigrama[0], mejor_binomial_bigrama[1])))\n","print(\"Bigrama-multinomial: Suavizado = %2.2f, F1 = %2.2f\" % ((mejor_multinomial_bigrama[0], mejor_multinomial_bigrama[1])))"],"metadata":{"id":"b4tieYas1mNY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilizando solo la puntuación F1 para obtener el mejor umbral, se encuentra que el utilizando unigramas el mejor resultado se da con un suavizado mínimo, 0.1, mientras que utilizando bigramas para la bolsa de palabras un buen umbral es 1.95 utilizando una distribución binomial y 0.15 para una distribución binomial. El mejor F1 lo da utilizando bigramas con una distribución multinomial."],"metadata":{"id":"ju4U9zQx7JnN"}},{"cell_type":"code","source":["# Obtiene más estadisticas para las mejores puntuaciones\n","\n","vectorizer  = CountVectorizer(ngram_range=(1, 1))\n","X = vectorizer.fit_transform(mails)          \n","X_test = vectorizer.transform(mails_test)\n","\n","bayesIngenuoBernoulli(0.1, True, True)\n","bayesIngenuoMultinomial(0.1, True, True)\n","\n","vectorizer  = CountVectorizer(ngram_range=(1, 2))\n","X = vectorizer.fit_transform(mails)          \n","X_test = vectorizer.transform(mails_test)\n","\n","bayesIngenuoBernoulli(1.95, True, True)\n","bayesIngenuoMultinomial(0.15, True, True)"],"metadata":{"id":"eWpXo-he8Ztk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A partir de la curva precision-recall, se prueba con distintos umbrales tal que se ajuste mejor a ella. Para ello se obtienen las probabilidades de que los correos sean clasificados correctamente."],"metadata":{"id":"J6W9F3SA7cLY"}},{"cell_type":"code","source":["# Crea y obtiene métricas para un clasificador mediante Bayes ingénuo utliizando\n","# distribuciones binomiales, dado un umbral personalizado. Imprime métricas \n","# y devuelve la puntuación F1\n","#\n","# suavizado: Hiperparámetro de suavizado de Laplace\n","# imprConfusion: Imprime matriz confusión\n","# imprPR: Imprime gráfica precision-recall\n","def bayesIngenuoBinomialDadoUmbral(suavizado, umbral, imprConfusion = False, imprPR = False):\n","  # Instancia el clasificador\n","  clasificador = BernoulliNB(alpha = suavizado)\n","\n","  # Calcula probabilidades utilizando los datos de entrenamiento\n","  clasificador.fit(X,y)\n","\n","  # Realiza clasificación con los datos de prueba, aplicando el umbral\n","  # a partir de las probabilidades de clasificar correctamente el dato\n","  y_prediccion = (clasificador.predict_proba(X_test)[:,1] >= umbral).astype(bool)\n","  print(\"Bayes ingénuo, distribución binomial, suavizado = %2.2f, umbral = %2.2f\" % (suavizado, umbral))\n","\n","  # Puntuación F1\n","  f1_score = metrics.f1_score(y_test, y_prediccion)\n","  print(\"\\nPuntuación F1: %2.2f\" % (100 * f1_score))\n","\n","  # Matriz de confusión\n","  if imprConfusion:\n","    confusion = metrics.confusion_matrix(y_test, y_prediccion)\n","    print(\"Matriz de confusión:\")\n","    print(confusion)\n","\n","  # Recta precision-recall\n","  if imprPR:\n","    metrics.plot_precision_recall_curve(clasificador, X_test, y_test)\n","\n","  print(\"\\n\")\n","\n","  return f1_score\n","\n","# Crea y obtiene métricas para un clasificador mediante Bayes ingénuo utliizando\n","# distribuciones multinomiales, dado un umbral personalizado. Imprime métricas \n","# y devuelve la puntuación F1\n","#\n","# suavizado: Hiperparámetro de suavizado de Laplace\n","# imprConfusion: Imprime matriz confusión\n","# imprPR: Imprime gráfica precision-recall\n","def bayesIngenuoMultinomialDadoUmbral(suavizado, umbral, imprConfusion = False, imprPR = False):\n","  # Instancia el clasificador\n","  clasificador = MultinomialNB(alpha = suavizado)\n","\n","  # Calcula probabilidades utilizando los datos de entrenamiento\n","  clasificador.fit(X,y)\n","\n","  # Realiza clasificación con los datos de prueba, aplicando el umbral\n","  # a partir de las probabilidades de clasificar correctamente el dato\n","  y_prediccion = (clasificador.predict_proba(X_test)[:,1] >= umbral).astype(bool)\n","  print(\"Bayes ingénuo, distribución multinomial, suavizado = %2.2f, umbral = %2.2f\" % (suavizado, umbral))\n","\n","  # Puntuación F1\n","  f1_score = metrics.f1_score(y_test, y_prediccion)\n","  print(\"\\nPuntuación F1: %2.2f\" % (100 * f1_score))\n","\n","  # Matriz de confusión\n","  if imprConfusion:\n","    confusion = metrics.confusion_matrix(y_test, y_prediccion)\n","    print(\"Matriz de confusión:\")\n","    print(confusion)\n","\n","  # Recta precision-recall\n","  if imprPR:\n","    metrics.plot_precision_recall_curve(clasificador, X_test, y_test)\n","\n","  print(\"\\n\")\n","\n","  return f1_score\n","\n","def mejorUmbralBinomial(suavizado):\n","  mejor_umbral = 0.0\n","  mejor_f1 = 0.0\n","  i = 0.05\n","\n","  while i <= 1.0:\n","    f1 = bayesIngenuoBinomialDadoUmbral(suavizado, i, True, False)\n","    if f1 > mejor_f1:\n","      mejor_f1 = f1\n","      mejor_umbral = i\n","    i += 0.05\n","\n","  return (mejor_umbral, mejor_f1)\n","\n","def mejorUmbralMultinomial(suavizado):\n","  mejor_umbral = 0.0\n","  mejor_f1 = 0.0\n","  i = 0.05\n","\n","  while i <= 1.0:\n","    f1 = bayesIngenuoMultinomialDadoUmbral(suavizado, i, True, False)\n","    if f1 > mejor_f1:\n","      mejor_f1 = f1\n","      mejor_umbral = i\n","    i += 0.05\n","\n","  return (mejor_umbral, mejor_f1)\n","\n","\n","vectorizer  = CountVectorizer(ngram_range=(1, 1))\n","X = vectorizer.fit_transform(mails)          \n","X_test = vectorizer.transform(mails_test)\n","\n","res1 = mejorUmbralBinomial(0.1)\n","res2 = mejorUmbralMultinomial(0.1)\n","\n","vectorizer  = CountVectorizer(ngram_range=(1, 2))\n","X = vectorizer.fit_transform(mails)          \n","X_test = vectorizer.transform(mails_test)\n","\n","res3 = mejorUmbralBinomial(1.95)\n","res4 = mejorUmbralMultinomial(0.15)\n","\n","print(\"Los mejores resultados para cada caso:\")\n","print(\"Unigrama-binomial: Suavizado = %2.2f, Umbral = %2.2f, F1 = %2.2f\" % ((0.1, res1[0], 100*res1[1])))\n","print(\"Unigrama-multinomial: Suavizado = %2.2f, Umbral = %2.2f, F1 = %2.2f\" % ((0.1, res2[0], 100*res2[1])))\n","print(\"Bigrama-binomial: Suavizado = %2.2f, Umbral = %2.2f, F1 = %2.2f\" % ((1.95, res3[0], 100*res3[1])))\n","print(\"Bigrama-multinomial: Suavizado = %2.2f, Umbral = %2.2f, F1 = %2.2f\" % ((0.15, res4[0], 100*res4[1])))"],"metadata":{"id":"QHDxGYLq8MSn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Obtiene más estadisticas para las mejores puntuaciones\n","\n","vectorizer  = CountVectorizer(ngram_range=(1, 1))\n","X = vectorizer.fit_transform(mails)          \n","X_test = vectorizer.transform(mails_test)\n","\n","bayesIngenuoBinomialDadoUmbral(0.1, 0.85, True, True)\n","bayesIngenuoMultinomialDadoUmbral(0.1, 0.35, True, True)\n","\n","vectorizer  = CountVectorizer(ngram_range=(1, 2))\n","X = vectorizer.fit_transform(mails)          \n","X_test = vectorizer.transform(mails_test)\n","\n","bayesIngenuoBinomialDadoUmbral(1.95, 0.95, True, True)\n","bayesIngenuoMultinomialDadoUmbral(0.15, 0.05, True, True)"],"metadata":{"id":"8Mhd-WA8I1MP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Conclusiones\n","\n","1. La distribución con la mejor puntuación F1 ajustados suavizado y umbral es la distribución multinomial utilizando bigramas, suavizado 0.15 y umbral 0.05.\n","2. La mejor puntuación F1 no significa que sea la mejor opción. Para el caso anterior, por ejemplo, se puede apreciar como la puntuación queda sesgada porque detecta mejor el correo spam a costa de mas falsos positivos de correos ham. Conforme aumenta el umbral de detección la situación comienza a revertirse: el filtro empeora la detección del correo spam con mas falsos negativos, pero se reduce la cantidad de falsos positivos que detecta.\n","3. Esta relación entre precisión (cuantos datos de un tipo han sido clasificados correctamente) y exhaustividad (cuantos datos no han sido malinterpretados como el contrario) se puede apreciar en las graficas precision-recall, en la curva de la esquina derecha. Es la región donde se pueden obtener los resultados con el mejor compromiso entre ambas."],"metadata":{"id":"aX8a1N4DIWZQ"}}]}